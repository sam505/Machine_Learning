{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYTORCH_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhKYWJKsE+saekEGEvnXwr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam505/Machine_Learning/blob/master/PYTORCH_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABEzEzSeJY4h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V76YVikSKXJP"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((28,28)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))\n",
        "                               ])\n",
        "\n",
        "train_batch_size = 32\n",
        "test_batch_size = 64\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root=\"/\", download=True, transform=transform, train=True)\n",
        "mnist_test = torchvision.datasets.MNIST(root=\"/\", download=True, transform=transform, train=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train,\n",
        "                                          shuffle=True,\n",
        "                                          batch_size=train_batch_size,\n",
        "                                          num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,\n",
        "                                          shuffle=False,\n",
        "                                          batch_size=test_batch_size,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCV4mCvPLD9H",
        "outputId": "142f345d-7d9a-45fd-edd6-5cec9272da72"
      },
      "source": [
        "len(mnist_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M6DcaWUOQPB",
        "outputId": "a630f358-e86d-48c6-c6d6-8bdd085ce5f3"
      },
      "source": [
        "len(mnist_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6NSzzubbFyX"
      },
      "source": [
        "writer = SummaryWriter()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzc6xHbxP4Up"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(LeNet, self).__init__()\n",
        "\t\tself.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
        "\t\tself.conv2 = nn.Conv2d(6, 16, (5,5))\n",
        "\t\tself.fc1   = nn.Linear(16*5*5, 120)\n",
        "\t\tself.fc2   = nn.Linear(120, 84)\n",
        "\t\tself.fc3   = nn.Linear(84, 10)\n",
        "\tdef forward(self, x):\n",
        "\t\tx = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "\t\tx = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "\t\tx = x.view(-1, self.num_flat_features(x))\n",
        "\t\tx = F.relu(self.fc1(x))\n",
        "\t\tx = F.relu(self.fc2(x))\n",
        "\t\tx = self.fc3(x)\n",
        "\t\treturn x\n",
        "\tdef num_flat_features(self, x):\n",
        "\t\tsize = x.size()[1:]\n",
        "\t\tnum_features = 1\n",
        "\t\tfor s in size:\n",
        "\t\t\tnum_features *= s\n",
        "\t\treturn num_features"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cAfbRfr94O8"
      },
      "source": [
        "def train(model, optimizer, epoch, train_loader, log_interval):\n",
        "    # State that you are training the model\n",
        "    model.train()\n",
        "\n",
        "    # define loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Iterate over batches of data\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Wrap the input and target output in the `Variable` wrapper\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        check_gpu = torch.cuda.is_available()\n",
        "        if check_gpu:\n",
        "          data = data.to(\"cuda\")\n",
        "          target = target.to(\"cuda\")\n",
        "\n",
        "        # Clear the gradients, since PyTorch accumulates them\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        output = model(data)\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters(weight,bias)\n",
        "        optimizer.step()\n",
        "\n",
        "        # print log\n",
        "        if batch_idx % log_interval == 0:\n",
        "            \n",
        "            print('Train set, Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader),\n",
        "                loss.data.item()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks55zQ0jcnst"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qkh4xkO-xBz"
      },
      "source": [
        "def test(model, epoch, test_loader):\n",
        "    # State that you are testing the model; this prevents layers e.g. Dropout to take effect\n",
        "    model.eval()\n",
        "\n",
        "    # Init loss & correct prediction accumulators\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # define loss function\n",
        "    loss_fn = nn.CrossEntropyLoss(size_average=False)\n",
        "\n",
        "    # Iterate over data\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        check_gpu = torch.cuda.is_available()\n",
        "        if check_gpu:\n",
        "          data = data.to(\"cuda\")\n",
        "          target = target.to(\"cuda\")\n",
        "\n",
        "        # Forward propagation\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate & accumulate loss\n",
        "        test_loss += loss_fn(output, target).data.item()\n",
        "\n",
        "        # Get the index of the max log-probability (the predicted output label)\n",
        "        pred = np.argmax(output.cpu().data, axis=1)\n",
        "\n",
        "        # If correct, increment correct prediction accumulator\n",
        "        correct = correct + np.equal(pred, target.cpu().data).sum()\n",
        "\n",
        "    # Print log\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set, Epoch {} , Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch,\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01vc7Xk89631",
        "outputId": "b318aab0-eb90-4243-80ff-cf9fea9e9558"
      },
      "source": [
        "# Provide seed for the pseudorandom number generator s.t. the same results can be reproduced\n",
        "torch.manual_seed(123)\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "check_gpu = torch.cuda.is_available()\n",
        "if check_gpu:\n",
        "\tmodel = model.cuda()\n",
        "\tprint ('USING GPU')\n",
        "else:\n",
        "\tprint ('USING CPU')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "log_interval = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, optimizer, epoch, train_loader, log_interval=log_interval)\n",
        "    test(model, epoch, test_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USING GPU\n",
            "Train set, Epoch 1 [0/60000 (0%)]\tLoss: 2.293154\n",
            "Train set, Epoch 1 [3200/60000 (5%)]\tLoss: 0.704558\n",
            "Train set, Epoch 1 [6400/60000 (11%)]\tLoss: 0.203603\n",
            "Train set, Epoch 1 [9600/60000 (16%)]\tLoss: 0.209678\n",
            "Train set, Epoch 1 [12800/60000 (21%)]\tLoss: 0.066283\n",
            "Train set, Epoch 1 [16000/60000 (27%)]\tLoss: 0.086467\n",
            "Train set, Epoch 1 [19200/60000 (32%)]\tLoss: 0.099034\n",
            "Train set, Epoch 1 [22400/60000 (37%)]\tLoss: 0.051752\n",
            "Train set, Epoch 1 [25600/60000 (43%)]\tLoss: 0.085965\n",
            "Train set, Epoch 1 [28800/60000 (48%)]\tLoss: 0.065832\n",
            "Train set, Epoch 1 [32000/60000 (53%)]\tLoss: 0.010793\n",
            "Train set, Epoch 1 [35200/60000 (59%)]\tLoss: 0.089628\n",
            "Train set, Epoch 1 [38400/60000 (64%)]\tLoss: 0.025988\n",
            "Train set, Epoch 1 [41600/60000 (69%)]\tLoss: 0.052667\n",
            "Train set, Epoch 1 [44800/60000 (75%)]\tLoss: 0.038602\n",
            "Train set, Epoch 1 [48000/60000 (80%)]\tLoss: 0.198402\n",
            "Train set, Epoch 1 [51200/60000 (85%)]\tLoss: 0.009598\n",
            "Train set, Epoch 1 [54400/60000 (91%)]\tLoss: 0.020831\n",
            "Train set, Epoch 1 [57600/60000 (96%)]\tLoss: 0.062915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set, Epoch 1 , Average loss: 0.0527, Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Train set, Epoch 2 [0/60000 (0%)]\tLoss: 0.041017\n",
            "Train set, Epoch 2 [3200/60000 (5%)]\tLoss: 0.031820\n",
            "Train set, Epoch 2 [6400/60000 (11%)]\tLoss: 0.084900\n",
            "Train set, Epoch 2 [9600/60000 (16%)]\tLoss: 0.009972\n",
            "Train set, Epoch 2 [12800/60000 (21%)]\tLoss: 0.014139\n",
            "Train set, Epoch 2 [16000/60000 (27%)]\tLoss: 0.012752\n",
            "Train set, Epoch 2 [19200/60000 (32%)]\tLoss: 0.072398\n",
            "Train set, Epoch 2 [22400/60000 (37%)]\tLoss: 0.038778\n",
            "Train set, Epoch 2 [25600/60000 (43%)]\tLoss: 0.067235\n",
            "Train set, Epoch 2 [28800/60000 (48%)]\tLoss: 0.072021\n",
            "Train set, Epoch 2 [32000/60000 (53%)]\tLoss: 0.008805\n",
            "Train set, Epoch 2 [35200/60000 (59%)]\tLoss: 0.006772\n",
            "Train set, Epoch 2 [38400/60000 (64%)]\tLoss: 0.198718\n",
            "Train set, Epoch 2 [41600/60000 (69%)]\tLoss: 0.010310\n",
            "Train set, Epoch 2 [44800/60000 (75%)]\tLoss: 0.146984\n",
            "Train set, Epoch 2 [48000/60000 (80%)]\tLoss: 0.264490\n",
            "Train set, Epoch 2 [51200/60000 (85%)]\tLoss: 0.113121\n",
            "Train set, Epoch 2 [54400/60000 (91%)]\tLoss: 0.002313\n",
            "Train set, Epoch 2 [57600/60000 (96%)]\tLoss: 0.004771\n",
            "\n",
            "Test set, Epoch 2 , Average loss: 0.0407, Accuracy: 9864/10000 (98.64%)\n",
            "\n",
            "Train set, Epoch 3 [0/60000 (0%)]\tLoss: 0.070881\n",
            "Train set, Epoch 3 [3200/60000 (5%)]\tLoss: 0.177258\n",
            "Train set, Epoch 3 [6400/60000 (11%)]\tLoss: 0.083609\n",
            "Train set, Epoch 3 [9600/60000 (16%)]\tLoss: 0.000931\n",
            "Train set, Epoch 3 [12800/60000 (21%)]\tLoss: 0.013919\n",
            "Train set, Epoch 3 [16000/60000 (27%)]\tLoss: 0.011730\n",
            "Train set, Epoch 3 [19200/60000 (32%)]\tLoss: 0.006513\n",
            "Train set, Epoch 3 [22400/60000 (37%)]\tLoss: 0.027572\n",
            "Train set, Epoch 3 [25600/60000 (43%)]\tLoss: 0.003883\n",
            "Train set, Epoch 3 [28800/60000 (48%)]\tLoss: 0.005396\n",
            "Train set, Epoch 3 [32000/60000 (53%)]\tLoss: 0.002060\n",
            "Train set, Epoch 3 [35200/60000 (59%)]\tLoss: 0.021835\n",
            "Train set, Epoch 3 [38400/60000 (64%)]\tLoss: 0.002679\n",
            "Train set, Epoch 3 [41600/60000 (69%)]\tLoss: 0.015271\n",
            "Train set, Epoch 3 [44800/60000 (75%)]\tLoss: 0.009691\n",
            "Train set, Epoch 3 [48000/60000 (80%)]\tLoss: 0.049069\n",
            "Train set, Epoch 3 [51200/60000 (85%)]\tLoss: 0.017149\n",
            "Train set, Epoch 3 [54400/60000 (91%)]\tLoss: 0.016045\n",
            "Train set, Epoch 3 [57600/60000 (96%)]\tLoss: 0.011528\n",
            "\n",
            "Test set, Epoch 3 , Average loss: 0.0339, Accuracy: 9885/10000 (98.85%)\n",
            "\n",
            "Train set, Epoch 4 [0/60000 (0%)]\tLoss: 0.001297\n",
            "Train set, Epoch 4 [3200/60000 (5%)]\tLoss: 0.012705\n",
            "Train set, Epoch 4 [6400/60000 (11%)]\tLoss: 0.000998\n",
            "Train set, Epoch 4 [9600/60000 (16%)]\tLoss: 0.005749\n",
            "Train set, Epoch 4 [12800/60000 (21%)]\tLoss: 0.004369\n",
            "Train set, Epoch 4 [16000/60000 (27%)]\tLoss: 0.000537\n",
            "Train set, Epoch 4 [19200/60000 (32%)]\tLoss: 0.143532\n",
            "Train set, Epoch 4 [22400/60000 (37%)]\tLoss: 0.000198\n",
            "Train set, Epoch 4 [25600/60000 (43%)]\tLoss: 0.008167\n",
            "Train set, Epoch 4 [28800/60000 (48%)]\tLoss: 0.003872\n",
            "Train set, Epoch 4 [32000/60000 (53%)]\tLoss: 0.009682\n",
            "Train set, Epoch 4 [35200/60000 (59%)]\tLoss: 0.002590\n",
            "Train set, Epoch 4 [38400/60000 (64%)]\tLoss: 0.128359\n",
            "Train set, Epoch 4 [41600/60000 (69%)]\tLoss: 0.000726\n",
            "Train set, Epoch 4 [44800/60000 (75%)]\tLoss: 0.004309\n",
            "Train set, Epoch 4 [48000/60000 (80%)]\tLoss: 0.066390\n",
            "Train set, Epoch 4 [51200/60000 (85%)]\tLoss: 0.003562\n",
            "Train set, Epoch 4 [54400/60000 (91%)]\tLoss: 0.093868\n",
            "Train set, Epoch 4 [57600/60000 (96%)]\tLoss: 0.201736\n",
            "\n",
            "Test set, Epoch 4 , Average loss: 0.0311, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "Train set, Epoch 5 [0/60000 (0%)]\tLoss: 0.001396\n",
            "Train set, Epoch 5 [3200/60000 (5%)]\tLoss: 0.015099\n",
            "Train set, Epoch 5 [6400/60000 (11%)]\tLoss: 0.000615\n",
            "Train set, Epoch 5 [9600/60000 (16%)]\tLoss: 0.089622\n",
            "Train set, Epoch 5 [12800/60000 (21%)]\tLoss: 0.000532\n",
            "Train set, Epoch 5 [16000/60000 (27%)]\tLoss: 0.067826\n",
            "Train set, Epoch 5 [19200/60000 (32%)]\tLoss: 0.019673\n",
            "Train set, Epoch 5 [22400/60000 (37%)]\tLoss: 0.167300\n",
            "Train set, Epoch 5 [25600/60000 (43%)]\tLoss: 0.007740\n",
            "Train set, Epoch 5 [28800/60000 (48%)]\tLoss: 0.004302\n",
            "Train set, Epoch 5 [32000/60000 (53%)]\tLoss: 0.010379\n",
            "Train set, Epoch 5 [35200/60000 (59%)]\tLoss: 0.034369\n",
            "Train set, Epoch 5 [38400/60000 (64%)]\tLoss: 0.000925\n",
            "Train set, Epoch 5 [41600/60000 (69%)]\tLoss: 0.024820\n",
            "Train set, Epoch 5 [44800/60000 (75%)]\tLoss: 0.001423\n",
            "Train set, Epoch 5 [48000/60000 (80%)]\tLoss: 0.016036\n",
            "Train set, Epoch 5 [51200/60000 (85%)]\tLoss: 0.032232\n",
            "Train set, Epoch 5 [54400/60000 (91%)]\tLoss: 0.003254\n",
            "Train set, Epoch 5 [57600/60000 (96%)]\tLoss: 0.094044\n",
            "\n",
            "Test set, Epoch 5 , Average loss: 0.0402, Accuracy: 9878/10000 (98.78%)\n",
            "\n",
            "Train set, Epoch 6 [0/60000 (0%)]\tLoss: 0.005773\n",
            "Train set, Epoch 6 [3200/60000 (5%)]\tLoss: 0.015430\n",
            "Train set, Epoch 6 [6400/60000 (11%)]\tLoss: 0.000577\n",
            "Train set, Epoch 6 [9600/60000 (16%)]\tLoss: 0.000342\n",
            "Train set, Epoch 6 [12800/60000 (21%)]\tLoss: 0.009232\n",
            "Train set, Epoch 6 [16000/60000 (27%)]\tLoss: 0.001132\n",
            "Train set, Epoch 6 [19200/60000 (32%)]\tLoss: 0.000938\n",
            "Train set, Epoch 6 [22400/60000 (37%)]\tLoss: 0.135327\n",
            "Train set, Epoch 6 [25600/60000 (43%)]\tLoss: 0.044998\n",
            "Train set, Epoch 6 [28800/60000 (48%)]\tLoss: 0.001830\n",
            "Train set, Epoch 6 [32000/60000 (53%)]\tLoss: 0.106027\n",
            "Train set, Epoch 6 [35200/60000 (59%)]\tLoss: 0.000766\n",
            "Train set, Epoch 6 [38400/60000 (64%)]\tLoss: 0.000312\n",
            "Train set, Epoch 6 [41600/60000 (69%)]\tLoss: 0.010965\n",
            "Train set, Epoch 6 [44800/60000 (75%)]\tLoss: 0.031199\n",
            "Train set, Epoch 6 [48000/60000 (80%)]\tLoss: 0.000083\n",
            "Train set, Epoch 6 [51200/60000 (85%)]\tLoss: 0.000497\n",
            "Train set, Epoch 6 [54400/60000 (91%)]\tLoss: 0.003636\n",
            "Train set, Epoch 6 [57600/60000 (96%)]\tLoss: 0.129523\n",
            "\n",
            "Test set, Epoch 6 , Average loss: 0.0341, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "Train set, Epoch 7 [0/60000 (0%)]\tLoss: 0.001457\n",
            "Train set, Epoch 7 [3200/60000 (5%)]\tLoss: 0.001480\n",
            "Train set, Epoch 7 [6400/60000 (11%)]\tLoss: 0.000475\n",
            "Train set, Epoch 7 [9600/60000 (16%)]\tLoss: 0.100120\n",
            "Train set, Epoch 7 [12800/60000 (21%)]\tLoss: 0.003205\n",
            "Train set, Epoch 7 [16000/60000 (27%)]\tLoss: 0.014697\n",
            "Train set, Epoch 7 [19200/60000 (32%)]\tLoss: 0.000806\n",
            "Train set, Epoch 7 [22400/60000 (37%)]\tLoss: 0.002037\n",
            "Train set, Epoch 7 [25600/60000 (43%)]\tLoss: 0.000676\n",
            "Train set, Epoch 7 [28800/60000 (48%)]\tLoss: 0.001680\n",
            "Train set, Epoch 7 [32000/60000 (53%)]\tLoss: 0.000396\n",
            "Train set, Epoch 7 [35200/60000 (59%)]\tLoss: 0.001580\n",
            "Train set, Epoch 7 [38400/60000 (64%)]\tLoss: 0.000675\n",
            "Train set, Epoch 7 [41600/60000 (69%)]\tLoss: 0.000146\n",
            "Train set, Epoch 7 [44800/60000 (75%)]\tLoss: 0.001039\n",
            "Train set, Epoch 7 [48000/60000 (80%)]\tLoss: 0.009163\n",
            "Train set, Epoch 7 [51200/60000 (85%)]\tLoss: 0.000916\n",
            "Train set, Epoch 7 [54400/60000 (91%)]\tLoss: 0.000629\n",
            "Train set, Epoch 7 [57600/60000 (96%)]\tLoss: 0.018628\n",
            "\n",
            "Test set, Epoch 7 , Average loss: 0.0381, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Train set, Epoch 8 [0/60000 (0%)]\tLoss: 0.020785\n",
            "Train set, Epoch 8 [3200/60000 (5%)]\tLoss: 0.008306\n",
            "Train set, Epoch 8 [6400/60000 (11%)]\tLoss: 0.010239\n",
            "Train set, Epoch 8 [9600/60000 (16%)]\tLoss: 0.001076\n",
            "Train set, Epoch 8 [12800/60000 (21%)]\tLoss: 0.000250\n",
            "Train set, Epoch 8 [16000/60000 (27%)]\tLoss: 0.000406\n",
            "Train set, Epoch 8 [19200/60000 (32%)]\tLoss: 0.000199\n",
            "Train set, Epoch 8 [22400/60000 (37%)]\tLoss: 0.000257\n",
            "Train set, Epoch 8 [25600/60000 (43%)]\tLoss: 0.000388\n",
            "Train set, Epoch 8 [28800/60000 (48%)]\tLoss: 0.000878\n",
            "Train set, Epoch 8 [32000/60000 (53%)]\tLoss: 0.002551\n",
            "Train set, Epoch 8 [35200/60000 (59%)]\tLoss: 0.000595\n",
            "Train set, Epoch 8 [38400/60000 (64%)]\tLoss: 0.008920\n",
            "Train set, Epoch 8 [41600/60000 (69%)]\tLoss: 0.000313\n",
            "Train set, Epoch 8 [44800/60000 (75%)]\tLoss: 0.004410\n",
            "Train set, Epoch 8 [48000/60000 (80%)]\tLoss: 0.000004\n",
            "Train set, Epoch 8 [51200/60000 (85%)]\tLoss: 0.003185\n",
            "Train set, Epoch 8 [54400/60000 (91%)]\tLoss: 0.002446\n",
            "Train set, Epoch 8 [57600/60000 (96%)]\tLoss: 0.007694\n",
            "\n",
            "Test set, Epoch 8 , Average loss: 0.0494, Accuracy: 9872/10000 (98.72%)\n",
            "\n",
            "Train set, Epoch 9 [0/60000 (0%)]\tLoss: 0.000049\n",
            "Train set, Epoch 9 [3200/60000 (5%)]\tLoss: 0.000102\n",
            "Train set, Epoch 9 [6400/60000 (11%)]\tLoss: 0.010467\n",
            "Train set, Epoch 9 [9600/60000 (16%)]\tLoss: 0.000019\n",
            "Train set, Epoch 9 [12800/60000 (21%)]\tLoss: 0.000075\n",
            "Train set, Epoch 9 [16000/60000 (27%)]\tLoss: 0.001060\n",
            "Train set, Epoch 9 [19200/60000 (32%)]\tLoss: 0.000148\n",
            "Train set, Epoch 9 [22400/60000 (37%)]\tLoss: 0.000601\n",
            "Train set, Epoch 9 [25600/60000 (43%)]\tLoss: 0.001848\n",
            "Train set, Epoch 9 [28800/60000 (48%)]\tLoss: 0.000446\n",
            "Train set, Epoch 9 [32000/60000 (53%)]\tLoss: 0.000061\n",
            "Train set, Epoch 9 [35200/60000 (59%)]\tLoss: 0.000841\n",
            "Train set, Epoch 9 [38400/60000 (64%)]\tLoss: 0.007641\n",
            "Train set, Epoch 9 [41600/60000 (69%)]\tLoss: 0.002847\n",
            "Train set, Epoch 9 [44800/60000 (75%)]\tLoss: 0.192796\n",
            "Train set, Epoch 9 [48000/60000 (80%)]\tLoss: 0.009342\n",
            "Train set, Epoch 9 [51200/60000 (85%)]\tLoss: 0.021699\n",
            "Train set, Epoch 9 [54400/60000 (91%)]\tLoss: 0.003926\n",
            "Train set, Epoch 9 [57600/60000 (96%)]\tLoss: 0.209111\n",
            "\n",
            "Test set, Epoch 9 , Average loss: 0.0423, Accuracy: 9891/10000 (98.91%)\n",
            "\n",
            "Train set, Epoch 10 [0/60000 (0%)]\tLoss: 0.011629\n",
            "Train set, Epoch 10 [3200/60000 (5%)]\tLoss: 0.007288\n",
            "Train set, Epoch 10 [6400/60000 (11%)]\tLoss: 0.000791\n",
            "Train set, Epoch 10 [9600/60000 (16%)]\tLoss: 0.000034\n",
            "Train set, Epoch 10 [12800/60000 (21%)]\tLoss: 0.018086\n",
            "Train set, Epoch 10 [16000/60000 (27%)]\tLoss: 0.053396\n",
            "Train set, Epoch 10 [19200/60000 (32%)]\tLoss: 0.000165\n",
            "Train set, Epoch 10 [22400/60000 (37%)]\tLoss: 0.000039\n",
            "Train set, Epoch 10 [25600/60000 (43%)]\tLoss: 0.000961\n",
            "Train set, Epoch 10 [28800/60000 (48%)]\tLoss: 0.000098\n",
            "Train set, Epoch 10 [32000/60000 (53%)]\tLoss: 0.000033\n",
            "Train set, Epoch 10 [35200/60000 (59%)]\tLoss: 0.154571\n",
            "Train set, Epoch 10 [38400/60000 (64%)]\tLoss: 0.033498\n",
            "Train set, Epoch 10 [41600/60000 (69%)]\tLoss: 0.000069\n",
            "Train set, Epoch 10 [44800/60000 (75%)]\tLoss: 0.000194\n",
            "Train set, Epoch 10 [48000/60000 (80%)]\tLoss: 0.002956\n",
            "Train set, Epoch 10 [51200/60000 (85%)]\tLoss: 0.002764\n",
            "Train set, Epoch 10 [54400/60000 (91%)]\tLoss: 0.000261\n",
            "Train set, Epoch 10 [57600/60000 (96%)]\tLoss: 0.000042\n",
            "\n",
            "Test set, Epoch 10 , Average loss: 0.0477, Accuracy: 9893/10000 (98.93%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wcXpSjFAB37",
        "outputId": "79c4e268-c0e1-4495-ad07-918997322c9e"
      },
      "source": [
        "len(mnist_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhF9tNjk37lS",
        "outputId": "b14236b4-49a0-4544-bab5-88ba322d1a14"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-14 17:41:32.410957: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "TensorBoard 2.5.0 at http://744932252c76:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIiaVm4g5sa3"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}