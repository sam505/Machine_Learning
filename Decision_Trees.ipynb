{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_Trees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObFjqwZvNrvpJ0IjQXx3jB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam505/Machine_Learning/blob/master/Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCwp2enqG0kf"
      },
      "source": [
        "## Importing necessary packages\n",
        "\n",
        "The required packages for this task will be pandas that has been used for loading the csv dataset, numpy to perform matrix operations and scikit-learn to define out training algorithm, split the dataset, and test the performance of the decision tree algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6fkK46wDTBj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH8cQvdKD5e2"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "We start by importing the csv file from an online database using pandas. The dataset has been downloaded from the University of California Irvine (UCI) Machine Learning (ML) Repository which contains numerous data generators, domain theories and dababases to be used by machine mearning practioners to test their machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9VXC88Df1U"
      },
      "source": [
        "def import_data():\n",
        "    data = pd.read_csv(\n",
        "        'https://archive.ics.uci.edu/ml/machine-learning-' +\n",
        "        'databases/balance-scale/balance-scale.data',\n",
        "        sep=',', header=None)\n",
        "\n",
        "    # Printing the shape of the dataset\n",
        "    print(\"Dataset Length: \", len(data))\n",
        "    print(\"Dataset Shape: \", data.shape)\n",
        "\n",
        "    # Printing the obseravtions of the dataset \n",
        "    print(\"Dataset Head: \", data.head())\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itQH9CONEQR4"
      },
      "source": [
        "## Splitting Dataset\n",
        "\n",
        "The next step after loading the dataset is to split it into data and labels. The data and labels are also split into the train and test sets. The train set is specifically for training the decision tree classifier for our data and later the test set will be used to test the accuracy of out decision tree algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh8jl9J2EHEY"
      },
      "source": [
        "def split_dataset(balance_data):\n",
        "    # Separating the target variable\n",
        "    X = balance_data.values[:, 1:5]\n",
        "    Y = balance_data.values[:, 0]\n",
        "\n",
        "    # Splitting the dataset into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, Y, test_size=0.3, random_state=100)\n",
        "\n",
        "    return X, Y, X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRahWmCxHPeV"
      },
      "source": [
        "## Training our algorithms\n",
        "\n",
        "For this task, I decided to train and test two different decision tree approaches, that is, train using entropy and train using gini. For both approaches there are contant configurations that I have set such as: the random state is 100, max depth will be 3, minimum sample leafs are 5. The different thing is the criterion used to train the decision tree  classifier. When usig entropy, I used the criterion variable as \"entropy\" and \"gini\" when training the classifier using Gini Index. The purpose of these two is to calculate the information gain useful when splitting a node. The both measure the impurity of a node in the essence that if a node has multiple classes it is classified as impure while that having only one class is pure. Below are the formulas used to caculate the impurity of a node for each of the two approches.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text { Gini }=1 &-\\sum_{i=1}^{n} p^{2}\\left(c_{i}\\right) \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text { Entropy } &=\\sum_{i=1}^{n}-p\\left(c_{i}\\right) \\log _{2}\\left(p\\left(c_{i}\\right)\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zte6-DUfKsBo"
      },
      "source": [
        "Defining the function for training with the Decision Tree algorithm using the entropy criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD0g2fLEHuqS"
      },
      "source": [
        "def train_using_entropy(X_train, X_test, y_train):\n",
        "    \"\"\"\n",
        "    Function to perform training with entropy\n",
        "    \"\"\"\n",
        "    # Decision tree with entropy\n",
        "    clf_entropy = DecisionTreeClassifier(\n",
        "        criterion=\"entropy\", random_state=100,\n",
        "        max_depth=3, min_samples_leaf=5)\n",
        "\n",
        "    # Performing training\n",
        "    clf_entropy.fit(X_train, y_train)\n",
        "    return clf_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQrF_4pdKyse"
      },
      "source": [
        "Defining the function for training the Decision Tree algorithm using the Gini Index criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoUCmq3qEwiG"
      },
      "source": [
        "def train_using_gini(X_train, X_test, y_train):\n",
        "    \"\"\"\n",
        "    Function to perform training with giniIndex\n",
        "    \"\"\"\n",
        "    # Creating the classifier object\n",
        "    clf_gini = DecisionTreeClassifier(criterion=\"gini\",\n",
        "                                      random_state=100, max_depth=3, min_samples_leaf=5)\n",
        "\n",
        "    # Performing training\n",
        "    clf_gini.fit(X_train, y_train)\n",
        "    return clf_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVCgUwd8K9Fx"
      },
      "source": [
        "Created a function to take in the classifier algorithm and also the test dataset and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfia500OKqRJ"
      },
      "source": [
        "def prediction(X_test, clf_object):\n",
        "    \"\"\"\n",
        "    Function to make predictions\n",
        "    \"\"\"\n",
        "    # Predicton on test with giniIndex\n",
        "    y_pred = clf_object.predict(X_test)\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUcZRnahMP11"
      },
      "source": [
        "This function takes the test labels and the predictions made by the decision tree model and compares them to get the values for the accuracy, confusion matrix and the general report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86FLdB26LFa8"
      },
      "source": [
        "def calculate_accuracy(y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracy\n",
        "    \"\"\"\n",
        "    print(\"Accuracy : {}\\n\".format(accuracy_score(y_test, y_pred) * 100))\n",
        "    print(\"Confusion Matrix: {}\\n\".format(confusion_matrix(y_test, y_pred)))\n",
        "    print(\"Report : {}\\n\".format(classification_report(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GEShSsMPS0L"
      },
      "source": [
        "Calling the funtions for loading the dataset and splitting it into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woGjJ5uJLv46",
        "outputId": "cedb287f-6947-4e55-f160-d6416e766404"
      },
      "source": [
        "data = import_data()\n",
        "X, Y, X_train, X_test, y_train, y_test = split_dataset(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length:  625\n",
            "Dataset Shape:  (625, 5)\n",
            "Dataset Head:     0  1  2  3  4\n",
            "0  B  1  1  1  1\n",
            "1  R  1  1  1  2\n",
            "2  R  1  1  1  3\n",
            "3  R  1  1  1  4\n",
            "4  R  1  1  1  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9x71A5NQfov"
      },
      "source": [
        "### Entropy Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhiOQt5YPWwR"
      },
      "source": [
        "entropy_classifier = train_using_entropy(X_train, X_test, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHMAa5h5QZUU",
        "outputId": "c1be02fb-14a6-4bbf-f275-fb088bfe1619"
      },
      "source": [
        "print(\"Results Using Entropy Approach\\n\")\n",
        "\n",
        "# Getting predictions using the entropy approach\n",
        "entropy_y_pred = prediction(X_test, entropy_classifier)\n",
        "calculate_accuracy(y_test, entropy_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results Using Entropy Approach\n",
            "\n",
            "Accuracy : 70.74468085106383\n",
            "\n",
            "Confusion Matrix: [[ 0  6  7]\n",
            " [ 0 63 22]\n",
            " [ 0 20 70]]\n",
            "\n",
            "Report :               precision    recall  f1-score   support\n",
            "\n",
            "           B       0.00      0.00      0.00        13\n",
            "           L       0.71      0.74      0.72        85\n",
            "           R       0.71      0.78      0.74        90\n",
            "\n",
            "    accuracy                           0.71       188\n",
            "   macro avg       0.47      0.51      0.49       188\n",
            "weighted avg       0.66      0.71      0.68       188\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGbHNaTzQip9"
      },
      "source": [
        "### Gini Index Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPLrMBy1PZSW"
      },
      "source": [
        "gini_classifier = train_using_gini(X_train, X_test, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOb1v6pzL2Ys",
        "outputId": "55c575d9-a6e5-4e95-ba23-555a01b35261"
      },
      "source": [
        "print(\"Results Using Gini Index Approach\\n\")\n",
        "\n",
        "# Getting prediction using Gini Index approach\n",
        "gini_y_pred = prediction(X_test, gini_classifier)\n",
        "calculate_accuracy(y_test, gini_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results Using Gini Index Approach\n",
            "\n",
            "Accuracy : 73.40425531914893\n",
            "\n",
            "Confusion Matrix: [[ 0  6  7]\n",
            " [ 0 67 18]\n",
            " [ 0 19 71]]\n",
            "\n",
            "Report :               precision    recall  f1-score   support\n",
            "\n",
            "           B       0.00      0.00      0.00        13\n",
            "           L       0.73      0.79      0.76        85\n",
            "           R       0.74      0.79      0.76        90\n",
            "\n",
            "    accuracy                           0.73       188\n",
            "   macro avg       0.49      0.53      0.51       188\n",
            "weighted avg       0.68      0.73      0.71       188\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v8VqgL5Oa0X"
      },
      "source": [
        "## Results\n",
        "\n",
        "Using the dataset obtained from UCI database, the decisin tree agorithm tained using the entropy approach had an accuracy of $\\text{70.74%}$ while the on etrained with the Gini Index approach it had an accuracy of $\\text{73.40%}$. For this case scenario I would train the classifier using the Gini Index approach because it has better accuracy results. The Gini Index approach also achieve better results whe it comes to the recall and precision. This makes it bes suited for this dataset. \n",
        "\n",
        "For better utilization of the code and to avoid rewritting the code for each trainig approach done, I defined functions that will be called when training, running predictions and also when calculating the results for each traiing approach. This is a best coding practice to reuse code for each scenario in the program. It also makes the code neater and easy to follow and understand the flow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjOsG6v_L2Wv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}